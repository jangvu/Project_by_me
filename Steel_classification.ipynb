{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Steel_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPBSuutXX9xJA4vpPYI+0SM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jangvu/Project_by_me/blob/main/Steel_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-zm8xfX0BHY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtanmtgRFHcE"
      },
      "source": [
        "!ls \"/content/drive/My Drive/Data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGGFMUFQFPee"
      },
      "source": [
        "!unzip -q \"/content/drive/My Drive/Data/NEU-DET.zip\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-cW_zL7AWyB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiyq4pO1DBlV"
      },
      "source": [
        "import csv \n",
        "#import requests \n",
        "import xml.etree.ElementTree as ET "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep5XU4jW39fy"
      },
      "source": [
        "# **Loading data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiiAlyi5Bmvd"
      },
      "source": [
        "IMAGES_PATH = '/content/IMAGES'\n",
        "ANNOTATIONS_PATH = '/content/ANNOTATIONS'\n",
        "\n",
        "IMAGES_DIR = os.listdir(IMAGES_PATH)\n",
        "ANNOTATIONS_DIR = os.listdir(ANNOTATIONS_PATH)\n",
        "\n",
        "images_arr = []\n",
        "annotations_arr = []\n",
        "for image in IMAGES_DIR:\n",
        "    images_arr.append(IMAGES_PATH + \"/\" + image)\n",
        "for annotation in ANNOTATIONS_DIR:\n",
        "    annotations_arr.append(ANNOTATIONS_PATH + \"/\" + annotation)\n",
        "\n",
        "images_arr.sort()\n",
        "annotations_arr.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdOScoO-w-up"
      },
      "source": [
        "## **Creating an ImageOject to save data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKqhyjPuw9-I"
      },
      "source": [
        "class imageObject:\n",
        "  def __init__(self,_filePath, _name, _label, _xmin, _ymin, _xmax, _ymax, _width = 200, _height = 200):\n",
        "    self.name = _name\n",
        "    self.label = _label\n",
        "    self.width = _width\n",
        "    self.height = _height\n",
        "    self.xmin = _xmin\n",
        "    self.ymin = _ymin\n",
        "    self.xmax = _xmax\n",
        "    self.ymax = _ymax\n",
        "    self.filePath = _filePath\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9aj3dYh1qmV"
      },
      "source": [
        "## **Resize Img and Bounding box**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4YY-foC2UH7"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSc82m9S1qBq"
      },
      "source": [
        "data_image = []\n",
        "labels_image = []\n",
        "boxes_image = []\n",
        "images_path = []\n",
        "new_size = 224\n",
        "size = 224\n",
        "boxed_image_arr = []\n",
        "\n",
        "\n",
        "#  data_image.append(img_to_array(image))\n",
        "\n",
        "#Bounding box Resize\n",
        "\n",
        "for i in range(len(annotations_arr)):\n",
        "    xmlFile = open(annotations_arr[i])\n",
        "    tree = ET.parse(xmlFile)\n",
        "    root = tree.getroot()\n",
        "    filePath = images_arr[i]\n",
        "    name = root.find('filename').text\n",
        "    label = name.split(\"_\")[0]\n",
        "\n",
        "    for boundingObject in root.findall('object'):\n",
        "        xmin = float(boundingObject.find('bndbox').find('xmin').text)/200\n",
        "        ymin = float(boundingObject.find('bndbox').find('ymin').text)/200\n",
        "        xmax = float(boundingObject.find('bndbox').find('xmax').text)/200\n",
        "        ymax = float(boundingObject.find('bndbox').find('ymax').text)/200\n",
        "        boxed_image_arr.append(imageObject(filePath, name, label, xmin, ymin, xmax, ymax))\n",
        "\n",
        "#Image Resize\n",
        "for img in boxed_image_arr:\n",
        "  image = load_img(img.filePath, target_size=(size,size))\n",
        "  data_image.append(img_to_array(image))\n",
        "  labels_image.append(img.label)\n",
        "  boxes_image.append([img.xmin, img.ymin, img.xmax, img.ymax])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxQXV3cgbaw1"
      },
      "source": [
        "print(labels_image[0])\n",
        "print(boxes_image[0])\n",
        "len(boxes_image)\n",
        "#x1,y1,x2,y2 = lambda x: x*200 for x in boxes_image[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koAMu1GD8Aqb"
      },
      "source": [
        "## **Normalize Image and OneHotCoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOz0tMOj7_D1"
      },
      "source": [
        "data_image = np.array(data_image, dtype=\"float32\") / 255.0\n",
        "labels_image = np.array(labels_image)\n",
        "boxes_image = np.array(boxes_image, dtype = \"float32\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUn_XaAc1giV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzS0bJSZDYxW"
      },
      "source": [
        "# perform one-hot encoding on the labels\n",
        "labelBinarizer = LabelBinarizer()\n",
        "labels_image = labelBinarizer.fit_transform(labels_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL08D1vnTjTN"
      },
      "source": [
        "img_train, img_test, label_train, label_test, box_train, box_test = train_test_split(data_image,labels_image,boxes_image, test_size = 0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqQ3PK-A96bN"
      },
      "source": [
        "print(len(img_train))\n",
        "print(len(label_train))\n",
        "len(img_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5JKIZyS4TpZ"
      },
      "source": [
        "# **Building Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x82zSjL4-Dk6"
      },
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# load the VGG16 network, ensuring the head FC layers are left off\n",
        "IMG_SHAPE = (size, size, 3)\n",
        "vgg=tf.keras.applications.VGG19(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')# freeze all VGG layers so they will *not* be updated during the\n",
        "# training process\n",
        "vgg.trainable = False\n",
        "# flatten the max-pooling output of VGG\n",
        "flatten = vgg.output\n",
        "flatten = Flatten()(flatten)\n",
        "# construct a fully-connected layer header to output the predicted\n",
        "# bounding box coordinates\n",
        "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(4, activation=\"sigmoid\", name=\"bounding_box\")(bboxHead)\n",
        "# construct the model we will fine-tune for bounding box regression\n",
        "# construct a second fully-connected layer head, this one to predict the class label\n",
        "softmaxHead = Dense(512, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(len(labelBinarizer.classes_), activation=\"softmax\", name=\"class_label\")(softmaxHead)\n",
        "# put together our model which accept an input image and then output\n",
        "# bounding box coordinates and a class label\n",
        "model_vgg16 = Model(inputs = vgg.input, outputs = (bboxHead, softmaxHead))\n",
        "\n",
        "losses = {\n",
        "    \"class_label\": \"categorical_crossentropy\",\n",
        "    \"bounding_box\": \"mean_squared_error\",\n",
        "}\n",
        "# define a dictionary that specifies the weights per loss (both the\n",
        "# class label and bounding box outputs will receive equal weight)\n",
        "lossWeights = {\n",
        "    \"class_label\": 1.0,\n",
        "    \"bounding_box\": 1.0\n",
        "}\n",
        "\n",
        "# model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# initialize the optimizer, compile the model, and show the model\n",
        "# summary\n",
        "\n",
        "def updateLearningRate(epoch, lr):\n",
        "    print(\"epoch: {}\\tlearning rate: {}\".format(epoch, lr))\n",
        "    if epoch < 10 :\n",
        "        lr = 0.01\n",
        "    elif epoch >= 10 and epoch < 50:\n",
        "        lr = 0.001\n",
        "    elif epoch >= 50:\n",
        "        lr = 0.0001\n",
        "    return lr\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=5)\n",
        "opt = Adam(lr = LEARNING_RATE, decay = LEARNING_RATE / NUM_EPOCHS)\n",
        "\n",
        "\n",
        "model_vgg16.compile(loss = losses, optimizer = opt, metrics = [\"accuracy\"], loss_weights = lossWeights)\n",
        "model_vgg16.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAPVJ6GJ_DQM"
      },
      "source": [
        "trainTargets = {\n",
        "    \"class_label\": label_train,\n",
        "    \"bounding_box\": box_train\n",
        "}\n",
        "# construct a second dictionary, this one for our target testing\n",
        "# outputs\n",
        "testTargets = {\n",
        "    \"class_label\": label_test,\n",
        "    \"bounding_box\": box_test\n",
        "}\n",
        "history = model_vgg16.fit(img_train,trainTargets,epochs = 100, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv0GloMmCWTg"
      },
      "source": [
        "model_vgg16.evaluate(img_test,testTargets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w9huN5RsvJL"
      },
      "source": [
        "losses = {\n",
        "    \"class_label\": \"categorical_crossentropy\",\n",
        "    \"bounding_box\": \"mean_squared_error\",\n",
        "}\n",
        "baseModel_res = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False,\n",
        "                                              input_tensor = Input(shape = (224, 224, 3)))\n",
        "\n",
        "flatten_res = baseModel_res.output\n",
        "flatten_res = Flatten()(flatten_res)\n",
        "# construct a fully-connected layer header to output the predicted\n",
        "# bounding box coordinates\n",
        "bboxHead_res = Dense(128, activation=\"relu\")(flatten_res)\n",
        "bboxHead_res = Dense(64, activation=\"relu\")(bboxHead_res)\n",
        "bboxHead_res = Dense(32, activation=\"relu\")(bboxHead_res)\n",
        "bboxHead_res = Dense(4, activation=\"sigmoid\", name=\"bounding_box\")(bboxHead_res)\n",
        "# construct the model we will fine-tune for bounding box regression\n",
        "# construct a second fully-connected layer head, this one to predict\n",
        "# the class label\n",
        "headModel_res = keras.layers.AveragePooling2D(pool_size = (7, 7))(baseModel_res.output)\n",
        "headModel_res = Flatten()(headModel_res)\n",
        "softmaxHead_res = Dense(512, activation=\"relu\")(headModel_res)\n",
        "softmaxHead_res = Dropout(0.5)(softmaxHead_res)\n",
        "softmaxHead_res = Dense(512, activation=\"relu\")(softmaxHead_res)\n",
        "softmaxHead_res = Dropout(0.5)(softmaxHead_res)\n",
        "softmaxHead_res = Dense(len(labelBinarizer.classes_), activation=\"softmax\", name=\"class_label\")(softmaxHead_res)\n",
        "# put together our model which accept an input image and then output\n",
        "# bounding box coordinates and a class label\n",
        "model_resnet152 = Model(inputs = baseModel_res.input, outputs = (bboxHead_res, softmaxHead_res))\n",
        "\n",
        "for layer in baseModel_res.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "model_resnet152.compile(loss = losses, optimizer = opt, metrics = ['accuracy'])\n",
        "model_resnet152.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9vseOQzsyk0"
      },
      "source": [
        "history_resnet = model_resnet152.fit(img_train,trainTargets, callbacks = [early_stopping],epochs = 200, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azg-gc7wutpa"
      },
      "source": [
        "pic1 = img_train[0]*255\n",
        "box1 = boxes_image[0]\n",
        "x1 = int(box1[0] * 200)\n",
        "y1 = int(box1[1] * 200)\n",
        "x2 = int(box1[2] * 200)\n",
        "y2 = int(box1[3] * 200)\n",
        "print(\"{}-{}-{}-{}\".format(x1, y1, x2, y2))\n",
        "pic1 = pic1.astype(np.uint8)\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "pic1 = Image.fromarray(pic1, 'RGB')\n",
        "pic1.save('pic1.jpg')\n",
        "image = cv2.imread(IMAGES_PATH + 'scratches_244.jpg')\n",
        "cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOi3dl8_2_gm"
      },
      "source": [
        "# **Plot image and box**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxouSfjvvWsV"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1euOLckSWs3V"
      },
      "source": [
        "images_path1 = IMAGES_PATH + \"/scratches_244.jpg\"\n",
        "annotation_path1 = ANNOTATIONS_PATH + \"/scratches_244.xml\"\n",
        "boxed_arr = []\n",
        "xmlFile = open(annotation_path1)\n",
        "tree = ET.parse(xmlFile)\n",
        "root = tree.getroot()\n",
        "filename = images_path1\n",
        "label = root.find('filename').text.split(\"_\")[0]\n",
        "for boundingObject in root.findall('object'):\n",
        "    xmin = boundingObject.find('bndbox').find('xmin').text\n",
        "    ymin = boundingObject.find('bndbox').find('ymin').text\n",
        "    xmax = boundingObject.find('bndbox').find('xmax').text\n",
        "    ymax = boundingObject.find('bndbox').find('ymax').text\n",
        "    boxed_arr.append(imageObject(images_path1, filename, label, xmin, ymin, xmax, ymax))\n",
        "        \n",
        "for imageObj in boxed_arr:\n",
        "    print(imageObj.name)\n",
        "    print(imageObj.label)\n",
        "    image = cv2.imread(imageObj.name)\n",
        "    image = cv2.imread(imageObj.filePath)\n",
        "#    image = imutils.resize(image, width=224)\n",
        "    (h, w) = image.shape[:2]\n",
        "    print(h)\n",
        "    print(w)\n",
        "    w1 = 200\n",
        "    w2 = 224\n",
        "#     image = cv2.resize(image, (w2, w2))\n",
        "    print(image.shape)\n",
        "#     (h, w) = image.shape[:2]\n",
        "    xmin = int(int(imageObj.xmin) * (w/w1))\n",
        "    ymin = int(int(imageObj.ymin) * (h/w1))\n",
        "    xmax = int(int(imageObj.xmax) * (w/w1))\n",
        "    ymax = int(int(imageObj.ymax) * (h/w1))\n",
        "    y = ymin - 10 if ymin - 10 > 10 else ymin + 10\n",
        "    # put text in the picture\n",
        "    cv2.putText(image, imageObj.label, (xmin, y), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 2)\n",
        "    # plot image and box\n",
        "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ns0HSqZs1J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}